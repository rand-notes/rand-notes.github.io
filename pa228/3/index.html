<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=author content><meta name=description content="Error function regularization function: technique used for tuning the function by adding an additional penalty term in the error function.
Loss function L – penalization of dissimilar results
Categorical Loss Functions Typical for classification problems
Cross entropy applied to Softmax is often called Softmax Loss
Focal Loss softmax for one object or sigmoid for multiple objects
Generalization of cross entropy: Designed for Retina-Net to alleviate class imbalance problem.
Focal loss (FL) adopts another approach to reduce loss for well-trained class."><meta name=keywords content><meta name=robots content="noodp"><meta name=theme-color content><link rel=canonical href=https://rand-notes.github.io/pa228/3/><title>recap 3 :: idk</title><link href=https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.5.0/css/flag-icon.min.css rel=stylesheet type=text/css><link rel=stylesheet href=/main.7209ab6422eb371a6b685a56274cc88eff3db604665c3bdb698389c0585d4211.css><meta itemprop=name content="recap 3"><meta itemprop=description content="Error function regularization function: technique used for tuning the function by adding an additional penalty term in the error function.
Loss function L – penalization of dissimilar results
Categorical Loss Functions Typical for classification problems
Cross entropy applied to Softmax is often called Softmax Loss
Focal Loss softmax for one object or sigmoid for multiple objects
Generalization of cross entropy: Designed for Retina-Net to alleviate class imbalance problem.
Focal loss (FL) adopts another approach to reduce loss for well-trained class."><meta itemprop=wordCount content="1258"><meta itemprop=image content="https://rand-notes.github.io"><meta itemprop=keywords content><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://rand-notes.github.io"><meta name=twitter:title content="recap 3"><meta name=twitter:description content="Error function regularization function: technique used for tuning the function by adding an additional penalty term in the error function.
Loss function L – penalization of dissimilar results
Categorical Loss Functions Typical for classification problems
Cross entropy applied to Softmax is often called Softmax Loss
Focal Loss softmax for one object or sigmoid for multiple objects
Generalization of cross entropy: Designed for Retina-Net to alleviate class imbalance problem.
Focal loss (FL) adopts another approach to reduce loss for well-trained class."><meta property="og:title" content="recap 3"><meta property="og:description" content="Error function regularization function: technique used for tuning the function by adding an additional penalty term in the error function.
Loss function L – penalization of dissimilar results
Categorical Loss Functions Typical for classification problems
Cross entropy applied to Softmax is often called Softmax Loss
Focal Loss softmax for one object or sigmoid for multiple objects
Generalization of cross entropy: Designed for Retina-Net to alleviate class imbalance problem.
Focal loss (FL) adopts another approach to reduce loss for well-trained class."><meta property="og:type" content="article"><meta property="og:url" content="https://rand-notes.github.io/pa228/3/"><meta property="og:image" content="https://rand-notes.github.io"><meta property="article:section" content="fi"><meta property="og:site_name" content="idk"></head><body><div class=container><header class=header><span class=header__inner><a href=/ style=text-decoration:none><div class=logo>title</div></a><span class=header__right><nav class=menu><ul class=menu__inner><li><a href=/posts>notes</a></li></ul></nav><span class=menu-trigger><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M0 0h24v24H0z" fill="none"/><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/></svg></span><span class="theme-toggle not-selectable"><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M22 41c10.4934.0 19-8.5066 19-19C41 11.5066 32.4934 3 22 3 11.5066 3 3 11.5066 3 22s8.5066 19 19 19zM7 22C7 13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22z"/></svg></span></span></span></header><div class=content><main class=post><div class=post-info></p></div><article><h2 class=post-title><a href=https://rand-notes.github.io/pa228/3/>recap 3</a></h2><div class=post-content><h1 id=error-function>Error function</h1><p>regularization function: technique used for tuning the function by adding an additional penalty term in the error function.</p><p>Loss function L – penalization of dissimilar results</p><h1 id=categorical-loss-functions>Categorical Loss Functions</h1><p>Typical for classification problems</p><p>Cross entropy applied to Softmax is often called Softmax Loss</p><h1 id=focal-loss>Focal Loss</h1><p>softmax for one object or sigmoid for multiple objects</p><p>Generalization of cross entropy: Designed for Retina-Net to alleviate class imbalance problem.</p><p>Focal loss (FL) adopts another approach to reduce loss for well-trained class. So whenever the model is good at detecting background, it will reduce its loss and reemphasize the training on the object</p><h1 id=segmentation-losses>Segmentation Losses</h1><p>Distribution-based: CE, TopK loss, Focal Loss
Compounded: ELL, Combo
Region-based: IoU, SS, Dice, Tversky
Boundary-based: Boundary Loss</p><h1 id=region-based-loses>Region-based Loses</h1><p>Precision = TP / (TP + FP)
Recall = TP / (TP + FN)
IoU = TP / (TP + FN + FP)
F1 = Dice</p><p>Tversky(0,1) = Precision
Tversky(1,0) = Recall
Tversky(1,1) = IoU
Tversky(0.5,0.5) = IoU</p><h1 id=regression-loss-functions>Regression Loss Functions</h1><p>MAE, MSE, MSLE</p><h1 id=object-detection>Object detection</h1><p>Object detection is treated like Classification + Localization. Use multitask loss (softmax for class + l2 for bounding box)</p><h1 id=multiple-objects-detection-idea>Multiple Objects Detection: Idea</h1><p>take every possible window and slide over image.</p><h1 id=viola--jones-face-detection>Viola & Jones Face Detection</h1><p>First real-time object detector: Developed for faces and often still in use</p><p>Three key improvements:</p><ul><li>Integral image for fast calculation of Haar-like features (Just three arithmetic operations regardless of window size!)</li><li>Selection of important visual features using AdaBoost</li><li>Focus-of-attention mechanism: Combination of classifiers in cascades</li></ul><h1 id=hog-for-human-detection>HOG for Human Detection</h1><p>Dense grids of histograms of oriented gradients</p><p>Counts occurrences of gradient orientations in localized image portions</p><p>The essential thought behind the histogram of oriented gradients descriptor is that local object appearance and shape within an image can be described by the distribution of intensity gradients or edge directions. The image is divided into small connected regions called cells, and for the pixels within each cell, a histogram of gradient directions is compiled.</p><h1 id=deformable-part-models>Deformable Part Models</h1><p>Objects represented by a collection of parts arranged in a deformable configuration
Spring-like connections between some pairs of parts
Models are defined by subwindows of a feature pyramids</p><h1 id=modern-object-detectors>Modern Object Detectors</h1><p>One-stage detector:</p><ul><li>Input (Image, Patch, Pyramid)</li><li>Backbone (VGG16, ResNets, &mldr;)</li><li>Neck (SPP, FPN, &mldr;)</li><li>Dense Prediction (YOLO, RetinaNet)
Two-stage detector:</li><li>One-stage detector</li><li>Sparse Prediction (R-CNN family, &mldr;)</li></ul><h1 id=multi-scale-processing>Multi-scale processing</h1><p>ImagePyramid can create a multi-resolution representation of an image to facilitate efficient multiscale processing. Typical image pyramids are Gaussian and Laplacian pyramids.</p><h1 id=spatial-pyramid-pooling-spp>Spatial Pyramid Pooling (SPP)</h1><p>Spatial Pyramid Pooling (SPP) is a pooling layer that removes the fixed-size constraint of the network, i.e. a CNN does not require a fixed-size input image. Specifically, we add an SPP layer on top of
the last convolutional layer. The SPP layer pools the features and generates fixed-length outputs, which are then fed into the fully-connected layers (or other classifiers). In other words, we perform
some information aggregation at a deeper stage of the network hierarchy (between convolutional layers and fully-connected layers) to avoid the need for cropping or warping at the beginning.</p><p>Basically: we can have arbitrary image -> cnn -> and we have output wxhx256 -> we make e.g. 3 pyramids: one for max-global pooling 1x1x256, one with 2x2x256 and one with output 4x4x256 -> this vectors we
concatanate and pass to fully-connected layer.</p><h1 id=feature-pyramid-networks-fpn>Feature Pyramid Networks (FPN)</h1><p>Feature Pyramid Network (FPN) is a feature extractor designed for such pyramid concept with accuracy and speed in mind. It replaces the feature extractor of detectors like Faster R-CNN and generates
multiple feature map layers (multi-scale feature maps) with better quality information than the regular feature pyramid for object detection.</p><p>FPN composes of a bottom-up and a top-down pathway. The bottom-up pathway is the usual convolutional network for feature extraction. As we go up, the spatial resolution decreases. With more high-level
structures detected, the semantic value for each layer increases.</p><p>SSD makes detection from multiple feature maps. However, the bottom layers are not selected for object detection. They are in high resolution but the semantic value is not high enough to justify its use
as the speed slow-down is significant. So SSD only uses upper layers for detection and therefore performs much worse for small objects.</p><p>overview:</p><ul><li>Down-sampling path</li><li>Up-sampling path</li><li>Corresponding levels connected by 1×1 bottlenecks</li><li>Leads to better detection of small objects</li><li>Similar to U-Net (feature maps cropped and copied)</li></ul><h1 id=r-cnn>R-CNN</h1><p>R-CNN uses selective search (SS) and on each region it applies big CNN (e.g. VGG)</p><h1 id=fast-r-cnn>Fast R-CNN</h1><p>First run whole image on VGG, then run SS on image features, on each region then run lightweight CNN.</p><h1 id=faster-r-cnn>Faster R-CNN</h1><p>Instead of SS uses Region Proposal Network.</p><h1 id=region-proposal-network>Region Proposal Network</h1><p>takes feature maps as input and pass them to some CNN (ZF or VGG), which results in e.g. 1x256 vector. We then use two FC layers to predict coordinates and objectness.</p><p>The objectness measures whether the box contains an object (2 classes, background and object)
For each location in the feature maps, RPN makes k guesses. Therefore RPN outputs 4×k coordinates and 2×k scores per location
RPN only guess offsets for anchors for given point.</p><p>Faster R-CNN deploys 9 anchor boxes: 3 different scales (size of anchors) at 3 different aspect ratio (width:height of anchor). Using 9 anchors per location, it generates 2 × 9 objectness scores and 4 × 9 coordinates per location.</p><h1 id=roi-pooling>ROI Pooling</h1><p>we often use CNN that needs fixed size input. ROI pooling allows us to warp(resize) ROIs to predefined shape.</p><p>Divide into a grid of roughly equal subregions (sometimes cannot be same sizes) and then practically same as normal max pooling</p><p>Region features have always the same size even if input regions have different sizes!</p><p>Problem: Slight misalignment due to snapping; different-sized subregions is weird</p><p>Let&rsquo;s have a region 6x6 and we need to have ROI of size 2x2. So we take region 3x3 max pool it and use for ouput.</p><h1 id=roi-align>ROI Align</h1><p>Divide into equal sized subregions (may not be aligned to grid!)</p><p>Sample features at regularly-spaced points in each subregion using bilinear interpolation</p><p>It removes the harsh quantization of RoI Pool</p><h1 id=mask-r-cnn>Mask R-CNN</h1><ul><li>Object Detection Without Anchors</li><li>Faster R-CNN extended by mask network that operates on each RoI and predicts a 28x28 binary mask.</li><li>Only small overhead over Faster R-CNN</li><li>Conceptually very simple and general idea</li><li>Masks predicted for each class</li></ul><h1 id=non-max-suppression>Non-max suppression</h1><ul><li>object detectors often output many overlapping detections</li><li>solution: post-process raw detections using non-max suppression (NMS)
&ndash; select next highest scoring box
&ndash; eliminate lower-scoring boxes with IoU threshold e.g. 0.7
&ndash; if any boxes remain GOTO 1</li><li>problem: NMS may eliminate &ldquo;good&rdquo; boxes when objects are highly overlapping &mldr; no good solution</li></ul><h1 id=single-shot-detectors>Single Shot Detectors</h1><p>Predicts both classes and boundary boxes at the same time</p><h1 id=evaluation>Evaluation</h1><p>TP = True Positives (Predicted as positive as was correct)
FP = False Positives (Predicted as positive but was incorrect); if <code>IoU &lt; 0.5</code>
FN = False Negatives (Failed to predict an object that was there)</p><p>Precision = TP / (TP + FP)
Recall = TP / (TP + FN)
IoU = Area of overlap / area of union</p><p>The mean Average Precision or mAP score is calculated by taking the mean AP over all classes and/or overall IoU
thresholds, depending on different detection challenges that exist.</p><p>recall - there are 10 persons in image, but net found only 7, then recall is 0.7</p><p>AP - area under precision-recall curve - to plot we are lowering the threshold for object to be classified (at the end of
net)</p><p>Mean average precision (mAP) = Mean over all classes</p></div></article><hr><div class=post-info></div></main></div><footer class=footer></footer><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script></div><script type=text/javascript src=/bundle.min.77414ca1a0d130043c129098d97cecf433ce369d23de8eaa91f5111f432729db1257c49a33b38203d4be241ef53dafecd99a1d2c350b75316b55a0bb6a2e150b.js integrity="sha512-d0FMoaDRMAQ8EpCY2Xzs9DPONp0j3o6qkfURH0MnKdsSV8SaM7OCA9S+JB71Pa/s2ZodLDULdTFrVaC7ai4VCw=="></script></body></html>