---
date: "2021-01-01T00:00:00Z"
url: fi/ma012/0
title: ma012 lec0
math: true
---

# Descriptive statistics
- summarizes sample data via summarization techniques and indexes
- frequency tables, moments (mean, variance, skewness, kurtoisis) and quantiles (median, quartiles, interquartiles spans), contingency tables, correlation coefficients

# Frequency distribution i.e. frequency list/table
is a list, table or graph that display the frequency of various outcomes in a sample

# Exploratory Data Analysis (EDA)
- analysis of sample data, usually via visualization methods
- frequency plots, boxplots, histograms, scatter plots, PCA

# Statistical Inference
- derives probability properties (arguments, distribution) of population based on analysis of sample data
- requires a model - establishing a assumptions about population and data sample
- point and interval parameter estimates (confidence intervals), testing statistics hypothesis, predictions, classifications, clustering

# Parametric methods
- model establish probability distribution or some set, parameters are being examined via these probability distributions
- most of classic methods like t-test, linear regression model, Multivariate regression

# Nonparametric methods
or distribution-free statistical methods do not depend on having a normal distribution and can be used with skewed data or with categorical data (Spearman's rho, Mann-Whitney, Wilcoxon Test)

# Semiparametric methods
- combination of parametric and nonparametric mothods
- Cox model of proportional risks in survival analysis

# Nominal data (categorical)
distinguishes different categories for qualitative variables; 
dummy code: gender, ethnic background
R: factor

# Ordinal data
data exists in categories that are ordered but differences cannot be determined or they are meaningless. (Example: 1st, 2nd, 3rd)
R: ordered factor

# Interval data
Differences between values can be found, but there is no absolute 0. (Temp. and Time),
R: numeric

# Ratio Data
data with an absolute 0. Ratios are meaningful. (Length, Width, Weight, Distance)

# Null Hypothesis (H0)
a statement that the performance of treatment groups is so similar that the groups must belong to the same population; a way of saying that the experimental manipulation had no important effect

- all level factors have same mean values

# Alternative hypothesis (H1)
The hypothesis that states there is a difference between two or more sets of data.

- at least one pair of level factors differ in mean value

# significance level (alpha)
The acceptable level of error selected by the researcher, usually set at 0.05;
what we compare our p-value to

# Power of a test
- The probability of correctly detecting a false null hypothesis
- could be increased by increasing sample data size

# classical statistical hypothesis testing; according to critical field
- establish H0 and H1
- establish model - i.e. statistics assumptions
- choose test and testing statistics T with known probability distribution (under the validity of H0)
- choose significance level (Î±) - usually 0.05
- compute observed values *t* of testing statistics *T*
- establish critical region *W* according to *H1* and *t*
- H0 is rejected, if $$t \in W$$

# statistical hypothesis testing; via p-value
- compute p-value *p*
- H0 is rejected, if $$p \lt \alpha$$

# p-value
The probability level which forms basis for deciding if results are statistically significant (not due to chance).

# t-test
a statistical test used to evaluate the size and significance of the difference between two means

# multiple testing
the more statistical tests we do, the more likely we are to make an erroneous inference (unless we adjust our significance threshold).

# ANOVA (analysis of variance)
-differences among MEANS of continuous (numerical) variables
-more flexible than t-tests-->can analyze differences among MORE THAN 2 groups (even if diff sample sizes)

# multiple comparison tests
statistical tests used to make pairwise comparisons to find which means differ significantly from one another in a one-factor multilevel design

- Tukey or Scheffe method

# Tukey's method
it's preferred especially in case that all partial random selections have approximately same range

# Scheffe method
it's recommended especially in case that partial random selections have distinctly different ranges.

# The means / minimalni (nulovy) model
$$Y_{i,j} = \mu + \epsilon_{i,j}$$

- \mu (micro, u) - grand mean of Y, same for all levels of factor A
- eps - stochaistic independent random variables with probability distribution N(0, \o^2)

# The effect model / jednoducheho trideni
$$Y_{i,j} = \mu + \alpha + \epsilon_{i,j}$$

- alpha - effect of i-th level of factor A

# Gran mean / spolecna stredni hodnota
$$M: \mu^{\wedge} = Y^{\wedge}$$

# effect i-th category in model M
$$\alpha^{\wedge}_{i} = Y^{-}_{i.} - Y^{-}_{..}$$

# mean value of i-th category in model M
$$\mu^{\wedge}_{i} = \mu^{\wedge} + \alpha^{\wedge}_{i} = Y^{-}_{i.}$$

# common part of mean value in submodel M_0
$$\mu^{\wedge} = Y^{-}$$

# Square sums describing variability
- Total sum of squares , SS / celkovy soucet ctvercu
- Between-groups SS / skupinovy soucet ctvercu
- Within-groups/error/residual SS / rezidualni soucet ctvercu

# Parameters estimates in models
- Gran mean / spolecna stredni hodnota
- effect i-th category in model M
- mean value of i-th category in model M
- common part of mean value in submodel M_0
