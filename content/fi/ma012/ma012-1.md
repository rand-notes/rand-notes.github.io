---
date: 2021-10-02
url: fi/ma012/1
title: "ma012 1"
---

- z method
- f distribution
- t test
- F test 


- Mnohonasobne porovnavani
- Tukeyho
- Scheffeho metoda
- Bartlettuv test
- Kruskal-Wallisuv Test
- Jednovyberovy Wilconxonuv test (signed rank test)
Dvouv ́ybˇerov ́y Wilcoxon ̊uv test (rank-sum test)



---

dvojne trideni 
hypotezy ve dvojnem trideni

linearni modely
Znam ́enkov ́y test (sign test)
Parovy znamenkovy test
ANOVA
Postup testovani ve dvojnem trideni
Dvojne trideni s interakcemi

Testovani v modelu s interakcemi
Interpretace indexu determinace R-squared

Index determinace

# Empirical distribution function

{{<image src="/images/edf.png" position="center" alt="edf">}}

# Error vs Residual

> Error (or disturbance) is theis the deviation of the observed value from the (unobservable) true value of quantity of interest

> Residual is the difference between the observed value and the estimated value of the quantity of interest

Residual = observed value - predicted value: \\(e = y - \hat{y}\\)

The distinction is most important in regression analysis, where the concepts are sometimes called the **regression errors** and **regression residuals** and were they lead to the concept of studentized
residuals.


# Degrees of freedom

> Degrees of freedom is the number of values in the final calculation of a statistic that are free to vary


# Z-test

> A z-test is a statistical test used to determine whether two population means are different when the variances are known and the sample size is large1.

The test statistic is assumed to have a normal distribution, and nuisance parameters such as standard deviation should be known in order for an accurate z-test to be performed.

- is a hypothesis test in which the z-statistic follows a normal distribution
- A **z-statistic**, or **z-score**, is a number representing the result from the z-test
- are closely related to t-tests, but t-tests are best performed when an experiment has a small sample size. 
- assume the standard deviation is known, while t-tests assume it is unknown.


# t-distribution

*or Student's t-distribution*

> is any continuous probability distribution that arise when astimating the mean of a **normally distributed** population in situations where the sample size is small and the population's standard
> deviation is unknown.

# t-test

*or student's t-test*
> is any statistical hypothesis test in which the test statistic follows a Student's t-dristribution under the null hypothesis.

Used to determine wheter the means of two groups are equal to each other. The assumption for the test is that both groups are sampled from normal distributions with equal variances. The null hypothesis
is that the two means are equal, and the alternative is that they are not. It is known that under the null hypothesis, we can calculate a t-statistic that will follow a t-distribution with \\( n1 + n2 -
2 \\) degrees of freedom.

There is also a widely used modification of the t-test, known as **Welch's t-test** that adjusts the number of degrees of freedom when the variances are thought not to be equal to each other.


```python
x = rnorm(10)
y = rnorm(10)
t.test(x, y)

"""
 Welch Two Sample t-test
 
 data:  x and y
 t = -1.6264, df = 16.666, p-value = 0.1226
 alternative hypothesis: true difference in means is not equal to 0
 95 percent confidence interval:
  -1.4494854  0.1886137
 sample estimates:
   mean of x   mean of y 
 0.007872345 0.638308171
"""
```


# F-distribution

*or F-ratio also known as Snedecor's F distribution or the Fisher–Snedecor distribution*

> is a continuous probability distribution that arises frequently as the null distribution of a test statistic, most notably in the ANOVA and other F-tests.

The F-distribution with \\(d_1\\) and \\(d_2\\) degrees of freedom is the distribution of:

$$X = \frac{S_1/d_1}{S_2/d_2}$$

where \\(S_1\\) and \\(S_2\\) are independent random variables with chi-square distributions respective degrees of freedom \\(d_1\\) and \\(d_2\\)

# F-test

> is any statistical test in which the test statistic has an F-distribution under the null hypothesis.

It is most often used when comparing statistical models that have been fitted to a data set, in order to identify the model that best fits the population from which the data were sampled. Exact "F-tests"
mainly arise when the models have been fitted to the data using least squares.

The test statistic can be obtained by computing the ration of the two variances \\( S_A^2 \\) and \\( S_B^2 \\)

$$F = \frac{S_A^2}{S_B^2}$$

The degrees of freedom are \\( n_A - a \\) (for the numerator) and \\( n_B -1 \\) (for the denominator)


# Chi-square distribution

*also chi-square or \\( \chi^2 \\)-distribution*

> with k degrees of freedom is the distribution of a sum of the squares of k independent standard normal random variables. 

if \\(Z_1, ..., Z_k \\) are independent, standard normal random variables, then sum of their squares:

$$Q=\sum^k_{i=1} Z_i^2$$

is distributed according to the chi-squared distribution with k degrees of freedom. This is usually denoted as:

$$Q \sim \chi^2 (k) \text{ or } Q \sim \chi^2_k $$

The chi-squared distribution has one parameter: a positive integer k that specifies the number of degrees of freedom (the number of random variables being summed, Zi s)



# Multiple Comparisons Problem

*or multiple comparisons, multiplicity or multiple testing problem*

> occurs when one considers a set of statistical inferences simultaneously or inders a subset of parameters selected based on the observed values.


## Tukey's Range Test

*or Tukey's test, Tukey method ...*

> is a single-step multiple comparsion procedure and statistical test. It can be used to find means that are significantly different from each other.

Tukey's test is based on a formula very similar to that of the t-test. In fact, Tukey's test is essentially a t-test, except that it corrects for family-wise error rate.

The formula for Tukey's test is:

$$q_s = \frac{Y_A - Y_B}{SE}$$

where Y_A is the larger of the two means being compared, Y_B is the smaller, and SE is the standard error of the sum of the means.


## Scheffé's method

> is a method for adjusting significance levels in a linear regression analysis to account for multiple comparsions.

It is particularly useful in ANOVA and in constructing simultaneous confidence bands for regressions involving basis functions.

# Bartlett's test

> is used to test homoscedasticity, that is, if multiple samples are from populations with equal variances.

Some statistical tests, such as the ANOVA assume that variances are equal across groups or samples, which can be verified with Bartlett's test.
If the corresponding p-value of the test statistic is less than some significance level (like α = .05) then we can reject the null hypothesis and conclude that not all groups have the same variance.

Sample output in R:  
```
	Bartlett test of homogeneity of variances

data:  clotting by diet
Bartlett's K-squared = 1.668, df = 3, p-value = 0.6441
```

If we assume significance level 0.05, we can reject null hypothesis (that clotting depends on diet).


# Levene's test

> is an inferential statistic used to asses the equality of variances for a variable calculated for two or more groups.


Levene's test is alternative to Bartlett but is often less sensitive. Rejecting hypothesis same as Bartlett's.

```
Levene's Test for Homogeneity of Variance (center = median)
      Df F value Pr(>F)
group  3  1.0109 0.4086
      20       
```


# ANOVA

We must met three assumptions: normality, equal variances, independence.

If p-value is smaller than significance level we reject the null hypothesis that the variances are equal across all groups.

## Normality

ANOVA assumes that each sample was drawn from a normally distributed population.

- Check the assumption visually using histograms or Q-Q plots.
- Check the assumption using formal statistical tests like Shapiro-Wilk, Kolmogorov-Smironov, Jarque-Barre, or D’Agostino-Pearson.


## Equal Variance

ANOVA assumes that the variances of the populations that the samples come from are equal.

- Check the assumption visually using boxplots.
- Check the assumption using a formal statistical tests like Bartlett’s or Levene's Test.

## Independence

The observations in each group are independent of the observations in every other group. The observations within each group were obtained by a random sample.



# Sign Test

> is a statistical method to test for consistent differences between pairs of observations

# Wilcoxon signed-rank test

*Jednovýběrový Wilcoxonův párový test*

> is a non-parametric statistical hypothesis test used either to test the location of a set of samples or to compare the locations of two populations using a set of matched samples.


# Mann–Whitney U test

*Dvouvýběrový Wilcoxonův párový test or Wilcoxon rank-sum test*

> is a non-parametric test of the null hypothesis that, for randomly selected values X and Y from two populations, the probability of X being greater than Y is equal to the probability of Y being greater
> than X.


# Van der Waerden test

is a statistical test that k population distribution functions are equal. Van der Waerden test converts the ranks from a standard Kruskal-Wallis one-way analysis of variance to quantiles of the standard
normal distribution.


# Kruskal–Wallis test

*or Kruskal–Wallis one-way analysis of variance or one-way ANOVA on ranks*

> is a non-parametric method for testing whether samples originate from the same distribution.
> 
> The parametric equivalent of the Kruskal–Wallis test is the ANOVA

It used for comparing two or more independent samples of equal or different sample sizes. It exteds the *Mann-Whitney U test*, which is used for comparing only two groups.



# Normality tests

normality tests are used to determine if a data set is well-modeled by a normal distribution and to compute how likely it is for a random variable underlying the data set to be normally distributed. 

## Kolmogorov–Smirnov test

*or KS test*

> is a nonparametric test of the equality of continuous, one dimensional probability distributions

It can be used to compare a sample with a reference probability distribution (one-sample KS) or to comapre two-samples (two-sample KS).

```R
ks.test(X, "pnorm", mean=..., sd=...)
```

## Pearson's chi-squared test
Test dobré shody

*\\(\chi^2\\)* test

> is a statistical test applied to sets of categorical data to evaluate how likely it is that any observed difference between the sets arose by chance. It is the most widely used of many chi-squared
> tests (Yates, likelihood ratio, portmanteau test in time series, etc.)

```R
chisq.test(X, p=...)
```


## Lilliefors test

> is a normality test based on the Kolmogorov–Smirnov test. It is used to test the null hypothesis that data come from a normally distributed population, when the null hypothesis does not specify which
> normal distribution; i.e., it does not specify the expected value and variance of the distribution.

```R
lillie.test(X)
```

## Other Normality Tests in R

```R
# Anderson–Darling test
ad.test(X)

# Cramér–von Mises test
cvm.test(X)

# Shapiro–Wilk test
shapirotest(X)

# D'Agostino's K-squared test
agostino.test(X)

# Jarque–Bera test
jarque.test(X)

# Q-Q plot
qqnorm(X)
# or
qqline(X)
```







