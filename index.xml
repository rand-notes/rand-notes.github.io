<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>idk</title><link>https://rand-notes.github.io/</link><description>Recent content on idk</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 02 Nov 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://rand-notes.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>lec 05</title><link>https://rand-notes.github.io/fi/iv111/5/</link><pubDate>Tue, 02 Nov 2021 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/fi/iv111/5/</guid><description/></item><item><title>lec 06</title><link>https://rand-notes.github.io/fi/iv111/6/</link><pubDate>Tue, 02 Nov 2021 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/fi/iv111/6/</guid><description/></item><item><title>cheatsheet</title><link>https://rand-notes.github.io/fi/ma012/cs/</link><pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/fi/ma012/cs/</guid><description>CPD - continuous probability distribution
T-distribution - CPD for astimating the mean of a normally distributed population with small size and unknown standard deviation T-test - t-distribution under null hypothesis
F-distribution - CPD used as null hypothesis in ANOVA and other F-tests. F-test &amp;ndash; F-distribution under null hypothesis
z-test - test whether two population means are different, when variances are known and sample size large
Tests Overview H_0 zamitneme pokud je p mensi nez alpha</description></item><item><title>lec 03</title><link>https://rand-notes.github.io/fi/iv126/3/</link><pubDate>Thu, 14 Oct 2021 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/fi/iv126/3/</guid><description>Population-based Metaheuristics Genetic Algorithms Evolution Strategies Genetic Programming Ant Colony Optimization Particle Swarm Optimization Bee Colony Artificial Immune Systems Estimation of Distribution Algorithms general algo:
t = 0 while not end_condition: generate_popul(P_t) # generate new population P_t+1 = choose_new_popul() t += 1 Basic division:
Algorithms using evolution
Solution in population is choosed and reproduced with operators (mutation and crossovering).
e.g. genetics algorithms, evolution strategies
Algorithms using memory (blackboard)</description></item><item><title>lec 2</title><link>https://rand-notes.github.io/fi/iv126/2/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/fi/iv126/2/</guid><description>Neighborhoods Definition: Function of neighborhood N is mapping \( N: S \rightarrow 2^S \), which assign every solution s from Z, set of solutions \( N(S) \subset S \)
Effective Algorithms for Searching in Very Large Neighborhoods space size: polynom of higher order of magnitude (n &amp;gt; 2)
main problem is indentification of improving neighborhoods or best neighbor without enumeration of whole neighborhood.
Ejection Chain e.g. Capacitated Vehicle Routing Problem</description></item><item><title>lec 1</title><link>https://rand-notes.github.io/fi/iv126/1/</link><pubDate>Tue, 05 Oct 2021 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/fi/iv126/1/</guid><description>Approximate Methods is usually understood to give an approximate solution, with some kind of guarantee of performace. i.e. it solves TSP, and the total cost is never off by more than a factor of 2.
Exploration (Diversification) Terms Diversification and Intensification are being used mostly in conjunction with population-based optimization techniques
consists of probing a much larger portion of the search space with the hope of finding other promising solutions that are yet to be refined.</description></item><item><title>lec 04</title><link>https://rand-notes.github.io/fi/iv111/4/</link><pubDate>Mon, 04 Oct 2021 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/fi/iv111/4/</guid><description>Covariance $$ E([X - E(X)][Y - E(Y)]) = \sum_{i, j} p_{x_i, y_j} [x_i - E(X)][y_j - E(Y)] $$
is called the covariance of X and Y and denoted Cov(X, Y)
Covariance measures linear dependence between two random variables. It is positive if the variables are correlated, and negative when anticorrelated.
e.g. when Y = aX, using E(Y) = aE(x) we have Cov(X, Y) = aVar(X)
we define the correlation coefficient \rho(X, Y) as the normalized covariance, i.</description></item><item><title>ma012 1</title><link>https://rand-notes.github.io/fi/ma012/1/</link><pubDate>Sat, 02 Oct 2021 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/fi/ma012/1/</guid><description>z method
f distribution
t test
F test
Mnohonasobne porovnavani
Tukeyho
Scheffeho metoda
Bartlettuv test
Kruskal-Wallisuv Test
Jednovyberovy Wilconxonuv test (signed rank test) Dvouv ́ybˇerov ́y Wilcoxon ̊uv test (rank-sum test)
dvojne trideni hypotezy ve dvojnem trideni
linearni modely Znam ́enkov ́y test (sign test) Parovy znamenkovy test ANOVA Postup testovani ve dvojnem trideni Dvojne trideni s interakcemi</description></item><item><title>ma012 2</title><link>https://rand-notes.github.io/fi/ma012/2/</link><pubDate>Sat, 02 Oct 2021 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/fi/ma012/2/</guid><description>Test (ne)korelovanosti Pearsonuv vyberovy korelacni koeficient \( \rho_{XY} \) je odhadem teoreticke korelace \( rho_{XY} \) mezi nahodnymi velicinami X a Y.
Test (ne)korelovanosti je vlastne testem vyznamnosti korelace \rho_(XY)
$$ H_0: \rho_{XY} \eq 0 H_1: \rho_{XY} \neq 0 $$
H_0 nezamitneme \( r_{XY} \approx 0 \): nekorelovanost = lineární nezávistlost X, Y. Pozor nekorelovanost neimplikuje stochastickou nezávistlost. H_0 zamitneme \( r_{XY} \approx 1 \): souhlasná lineární závislost X, Y H_0 zamitneme \( r_{XY} \approx -1 \):nesouhlasná lineární závislost X, Y</description></item><item><title>Confidence Intervals</title><link>https://rand-notes.github.io/fi/ma012/conf-intervals/</link><pubDate>Thu, 30 Sep 2021 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/fi/ma012/conf-intervals/</guid><description>Statistical Inference is the process of drawing conclusions about populations or scientific truths from data
There are two types of statistical inferences; estimation and statistical (hypothesis) tests
Estimation Use information from the sample to estimate (or predict) the parameter of interest.
For instance, using the result of a poll about the president&amp;rsquo;s current approval rating to estimate (or predict) his or her true current approval rating nationwide.
Point Estimates</description></item><item><title>ma012 lec0</title><link>https://rand-notes.github.io/fi/ma012/0/</link><pubDate>Tue, 28 Sep 2021 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/fi/ma012/0/</guid><description>A bell curve is a graph depicting the normal distribution
p-value A p-value is a measure of the probability that an observed difference could have occurred just by random chance. p-values are numbers in interval (0, 1) and commonly used threshold is 0.05. The lower the p-value, the greater the statistical significance of the observed difference. While a small p-value helps us decide if one group differs from another, it does not tell us how different they are.</description></item><item><title>IV111 lec 03</title><link>https://rand-notes.github.io/fi/iv111/3/</link><pubDate>Sun, 26 Sep 2021 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/fi/iv111/3/</guid><description>Expectation of Random Variables Often we need a shorter description than PMF or CDF - single number, or a few number. First such characteristic describing a random variable is the expectation, also known as the mean value Expectation of a random varialbe X is defined as:
$$E(X) = \sum_{x\in lm(X)} x \cdot P(X = x)$$
provided the sum is absolutely convergent. In case the sum is convergent, but not absoutely convergent, we say that no finite expectation exists.</description></item><item><title>Environments, Agents, Optimizations</title><link>https://rand-notes.github.io/fi/iv126/0/</link><pubDate>Thu, 02 Sep 2021 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/fi/iv126/0/</guid><description>Environments Fully Observable vs Partially Observable If an agent&amp;rsquo;s sensors give it access to the complete state of the environment at each point in time, then we say that he task environment is fully observable. If the agents has no sensors at all then the environment is unobservable
Single-Agent vs Multi-Agent Environments For example, an agent solving a crossword puzzle by itself is clearly in a single-agent enviroment, whereas an agent playing chess is in a two-agent enviroment.</description></item><item><title>cpp</title><link>https://rand-notes.github.io/cpp/2021-01-01-cpp/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/cpp/2021-01-01-cpp/</guid><description/></item><item><title>DL0</title><link>https://rand-notes.github.io/dl0/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/dl0/</guid><description>TOC Underflow
Overflow
Softmax
Problems Condition number
Gradient-Based Optimization objective function; criterio; cost function; loss function; Gradient Descent; critical points; stationary points; local minumum; local maximum; Saddle points; global minimum; partial derivatives; gradient; directional derivative; method of steepest descent; gradient descent; Chain rule; Steepest descent proposes a new point; learning rate; line search; hill climbing; Jacobian matrix; second derivative; Hessian matrix; Jacobian; Hessian; second derivative test; Newton&amp;rsquo;s method; first-order optimization algorithms; second-order optimization algorithms; Lipschitz continous; Lipschitz constant; convex optimization;</description></item><item><title>DL1</title><link>https://rand-notes.github.io/dl1/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/dl1/</guid><description>TOC
self-information nats; bits; shannons;
Shannon entropy
KL Divergence
CrossEntropy
Factorization
Structured Probabilistic Model
Directed
Undirected The graph are just representation, any probability distribution can be described by both graphs. Graphs are not property of distributions;
Self-information we rate information value much higher if information is less likely and independent.</description></item><item><title>DL2</title><link>https://rand-notes.github.io/dl2/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/dl2/</guid><description>TOC Learning algorithms
The Task, T
Classification
Classification with missing inputs
Regression
Transcription
Machine translation
Structured output
Anomaly detection
Synthesis and sampling
Imputation of missing values
Denoising
Density estimation or probability mass function estimation
The Performance Measure, P accuracy; error rate;</description></item><item><title/><link>https://rand-notes.github.io/fi/iv126/task/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/fi/iv126/task/</guid><description>fyzicke stroje p \in P virtualni stroje v \in C
R(v, r) udava, kolik zdroje r vyuziva virtualni stroj v C(p, r) udava jakou kapacitu zdroje r je mozne na fyzickem stroji p naaalokavat SC(p, r) bezpecna kapacita zdroje r na fyzickem stroji p
plati: SC(p, r) &amp;lt; C(p, r)
MC(v) cena za migraci virtualniho stroje v PMC(p, p') cena za migraci libovolneho virtualniho stroje z fyzickeho stroje p na fyzicky stroj p'.</description></item><item><title/><link>https://rand-notes.github.io/fi/ma012/cheatsheet2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/fi/ma012/cheatsheet2/</guid><description># PCA # cor=TRUE =&amp;gt; pracuje s korelacni matici misto kovariancni, tj. standardizuje vsechny veliciny # scores=TRUE =&amp;gt; spocita i koeficienty pozorovani v hlavnich komponentach pca &amp;lt;- princomp(X, cor = TRUE, scores = TRUE) pca$scores Variance inflation factor (VIF) is a measure of the amount of multicollinearity in a set of multiple regression variables
vif(model) # VIF = variance inflation factors model &amp;lt;- lm(vydaje ~ ., data = domacnosti) # klasicky LRM # Stepwise regressiom # backward model.</description></item><item><title/><link>https://rand-notes.github.io/fi/pa163/1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/fi/pa163/1/</guid><description>Omezení Množina doménových proměnných Y = {y_1, &amp;hellip;, y_k} Konečná množina hodnota (doména) D = D_1 \cup D_2 \cup D-k
Omezení (podmínka) c na Y je podmnožina D_1 x &amp;hellip; x D_k tj. relace
příklad:
promenne: A, B domény: {0, 1} pro A; {1,2} pro B omezení: A != B
Problém splňování podmínek (CSP) konečná množina proměnných X = {x1,&amp;hellip;,xn} konečná množina hodnot (doména) D = D1 \cup &amp;hellip; \cup Dn konečná množina omezení C = {c1,&amp;hellip;,cm}</description></item><item><title>0</title><link>https://rand-notes.github.io/fi/iv111/0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/fi/iv111/0/</guid><description>Countable Addiitivity Axiom If \( A_1, A,2, &amp;hellip; \) is an infinite sequence of disjoint events, then \( P(A_1 \cup A_2 \cup A_3 \cup &amp;hellip;) = P(A_1) + P(A_2) + P(A_3) + &amp;hellip; \)
Addiitivity holds only for countable sequences of events
The unit square (similarly, the real line etc) is not countable (its elements cannot be arranged in a sequence)</description></item><item><title>adadas</title><link>https://rand-notes.github.io/ai/exam2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/ai/exam2/</guid><description>basic/pokrocile prohledavani == grafy
ejection chain; cyclic exchange
hill climbing simulovane zihani - akceptuje i horsi threshold accepting - akceptuje s max zhorsenim o prah potopa - zmenusujeme hladinu tabu seznam - muzeme overridnout pomoci aspiracniho kriteria
Multistart local search, Iterativní lokální prohledávání
VNS - variable neighborhood search VND - variable neighborhood descent
deterministicka verze VNS rozsirujeme okoli, po uspechu jedeme od zacatky GLS - guided local search</description></item><item><title>algos</title><link>https://rand-notes.github.io/ai/exam/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/ai/exam/</guid><description>k-opt TODO
k-distance TODO
Ejection Chain řetězec odstranění: posloupnost přesunů zákazníka z jednoho okruhu na následující úspěšná změna: žádný vrchol není v řešení více než jednou řetězec odstranění nemusí být cyklický (stačí umístit konzistentně posledního zákazníka do posledního okruhu) postup každý řetězec odstranění zahrnuje k úrovní začínajících na okruhu 1 a končících na okruhu k vrchol je odstraněn z okruhu 1 a přesunut na okruh 2, vrchol z okruhu 2 přesunut na okruh 3, atd.</description></item><item><title>cheatsheet1</title><link>https://rand-notes.github.io/exam1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/exam1/</guid><description>Anova Predpoklady faktor A (popr. B) musi mit 3 a vic urovni Normalita hodnot jednotlivých náhodných výběrů Stejný rozptyl hodnot ve všech srovnávaných skupinách Nezávislost pozorovaných hodnot (casto se bere automaticky) Hypotezy HA0: vsechny stredni hodnoty v radcich jsou stejne tj. faktor A nema vliv HA1: nektere dvojice strednich hodnot v radcich se lisi tj. faktor A ma vliv HB0: vsechny stredni hodnoty v sloupcich jsou stejne tj. faktor B nema vliv HB1: nektere dvojice strednich hodnot v sloupcich se lisi tj.</description></item><item><title>cheatsheet1</title><link>https://rand-notes.github.io/exam2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/exam2/</guid><description>Model vícenásobné lineárníj regrese Slouží k modelování jednorozměrné náhodné veličiny Y skupinou p náhodných veličin X1,&amp;hellip;,Xp. Vycházíme ze znalosti (p+1)-dimenzionálního náhodného výběru rozsahu n. Model mnohonásobné lineární regrese zapíšeme ve tvaru Y=X*Beta. Y je vektor (Y1,..Yn), Beta je vektor (B0,B1, &amp;hellip;,Bn), kde B1,..,Bn jsou lineární koeficienty náhodných veličin X1,&amp;hellip;,Xp. X je matice, která má první sloupec jednotkový, a další sloupce tvoří náhodné výběry rozsahu n jednotlivých náhodných veličin. Model řešíme odhadem parametrů metodou nejmenších čtverců.</description></item><item><title>exam</title><link>https://rand-notes.github.io/iv111/exam/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/iv111/exam/</guid><description>Events A1, A2, . . . An are (mutually) independent iff for any set {i1, i2, . . . ik }⊆{1 . . . n} (2 ≤k ≤n) of distinct indices it holds that P (Ai1 ∩Ai2 ∩···∩Aik ) = P (Ai1 )P (Ai2 ) . . . P (Aik ).
Events A1, A2, . . . An are pairwise independent iff for all distinct indices i , j ∈{1 .</description></item><item><title>Examples</title><link>https://rand-notes.github.io/fi/ma012/ex/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/fi/ma012/ex/</guid><description>Ex 1 On significance level 0.05, test null hypothesis that mean values for X are same for all groups Y.
Steps:
Bartlett and Levene -&amp;gt; ANOVA -&amp;gt; Tukey and Scheffe Ex 2 Let&amp;rsquo;s have two random vectors X = (2, 4, 6, 8) a Y = (1, 3, 5, 7).
Compute Kendall \( \tau \) and number of concordant pairs:
res&amp;lt;-cor.test(X, Y, method=&amp;quot;kendall&amp;quot;) res The result will be:
Kendall's rank correlation tau data: Y and X T = 6, p-value = 0.</description></item><item><title>math 0</title><link>https://rand-notes.github.io/math/0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/math/0/</guid><description>Pursuit Curve A curve of pursuit is a curve constructed by analogy to having a point or points representing pursuers and pursuees; the curve of pursuit is the curve traced by the pursuers. With the paths of the pursuer and pursuee parameterized in time, the pursuee is always on the pursuer&amp;rsquo;s tangent.
e.g. one plane chasing another. The plane that is being chased must have predetermined path (flying upwards, in circle etc.</description></item><item><title>overview 1</title><link>https://rand-notes.github.io/fi/ma012/cs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/fi/ma012/cs/</guid><description>CPD - continuous probability distribution
T-distribution - CPD for astimating the mean of a normally distributed population with small size and unknown standard deviation T-test - t-distribution under null hypothesis
F-distribution - CPD used as null hypothesis in ANOVA and other F-tests. F-test &amp;ndash; F-distribution under null hypothesis
z-test - test whether two population means are different, when variances are known and sample size large
Tests Overview H_0 zamitneme pokud je p mensi nez alpha</description></item><item><title>overview 2</title><link>https://rand-notes.github.io/fi/ma012/overview2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/fi/ma012/overview2/</guid><description>2 cviko Na hladine vyznamnosti testujte nulovou hypotezu, ze stredni hodnoty trzeb vsechno proddavacu se rovnaji. Spocitejte ze hmotnost brambor nesouvisi s odrudou.
reseni: Levene a Bartletts test pro overeni ze variance(rozptyl) je podobna mezi skupinami Shapiruv-Wilkeuv a Kolmogorovuv-Smirnovuv test pro overeni normality ANOVA pro testovani stredni hodnoty Tukey a Scheffe pro porovnani ktere dvojice se nejvic lisi
R:
leveneTest(tabulka$hmotnost ~ tabulka$odruda) # odruda musi byt factor bartlett.test(tabulka$hmotnost ~ tabulka$odruda)</description></item><item><title>PA163 lec 2</title><link>https://rand-notes.github.io/fi/pa163/2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/fi/pa163/2/</guid><description>Grafová reprezentace CSP Reprezentace podmínek intenzionální (matematická/logická formule) extenzionální (výčet k-tic kompatibilních hodnot, 0-1 matice) Graf: vrcholy, hrany (hrana spojuje dva vrcholy) Hypergraf: vrcholy, hrany (hrana spojuje množinu vrcholů) Reprezentace CSP pomocí hypergrafu podmínek: vrchol = proměnná, hyperhrana = podmínka Hypergraf Hypergraf je pojem z teorie grafů. Jedná se o zobecnění pojmu graf. Rozdíl je v tom, že hrany hypergrafu (hyperhrany) mohou spojovat libovolný počet vrcholů, zatímco u grafu spojují hrany vždy dva vrcholy.</description></item><item><title>pa163 lec03</title><link>https://rand-notes.github.io/fi/pa163/3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://rand-notes.github.io/fi/pa163/3/</guid><description>Konzistence po cestě (PC path consistency) PC-2 Postup Promazu domeny pomoci inicialnich relaci &amp;ndash; kdyz mam V_1 != V_2 vymazu v domene V1 vsechny dvojice, kde V_1 == V_2 do fronty si vlozim vsechny cesty [1] vezmeme z fronty a provedeme revizi pokud pri revizi neco zmenim pridam do queue podle [2] [1] - nejlepe se to dela ze vezmu ze jdu pres vsechny body. napr mame V_1, V_2, V_3 ve trojuhelniku &amp;ndash; do fronty vlozime (V_1, V_2, V_3),(V_1, V_3, V_2),(V_2, V_1, V_3).</description></item></channel></rss>