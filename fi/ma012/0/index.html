<!doctype html><html lang=en>
<head>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="ie=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=author content>
<meta name=description content="A bell curve is a graph depicting the normal distribution
 p-value A p-value is a measure of the probability that an observed difference could have occurred just by random chance. p-values are numbers in interval (0, 1) and commonly used threshold is 0.05. The lower the p-value, the greater the statistical significance of the observed difference. While a small p-value helps us decide if one group differs from another, it does not tell us how different they are.">
<meta name=keywords content>
<meta name=robots content="noodp">
<meta name=theme-color content>
<link rel=canonical href=https://rand-notes.github.io/fi/ma012/0/>
<title>
ma012 lec0 :: idk
</title>
<link href=https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.5.0/css/flag-icon.min.css rel=stylesheet type=text/css>
<link rel=stylesheet href=/main.7209ab6422eb371a6b685a56274cc88eff3db604665c3bdb698389c0585d4211.css>
<meta itemprop=name content="ma012 lec0">
<meta itemprop=description content="A bell curve is a graph depicting the normal distribution
 p-value A p-value is a measure of the probability that an observed difference could have occurred just by random chance. p-values are numbers in interval (0, 1) and commonly used threshold is 0.05. The lower the p-value, the greater the statistical significance of the observed difference. While a small p-value helps us decide if one group differs from another, it does not tell us how different they are."><meta itemprop=datePublished content="2021-09-28T00:00:00+00:00">
<meta itemprop=dateModified content="2021-09-28T00:00:00+00:00">
<meta itemprop=wordCount content="1051"><meta itemprop=image content="https://rand-notes.github.io">
<meta itemprop=keywords content>
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://rand-notes.github.io">
<meta name=twitter:title content="ma012 lec0">
<meta name=twitter:description content="A bell curve is a graph depicting the normal distribution
 p-value A p-value is a measure of the probability that an observed difference could have occurred just by random chance. p-values are numbers in interval (0, 1) and commonly used threshold is 0.05. The lower the p-value, the greater the statistical significance of the observed difference. While a small p-value helps us decide if one group differs from another, it does not tell us how different they are.">
<meta property="og:title" content="ma012 lec0">
<meta property="og:description" content="A bell curve is a graph depicting the normal distribution
 p-value A p-value is a measure of the probability that an observed difference could have occurred just by random chance. p-values are numbers in interval (0, 1) and commonly used threshold is 0.05. The lower the p-value, the greater the statistical significance of the observed difference. While a small p-value helps us decide if one group differs from another, it does not tell us how different they are.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://rand-notes.github.io/fi/ma012/0/"><meta property="og:image" content="https://rand-notes.github.io"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2021-09-28T00:00:00+00:00">
<meta property="article:modified_time" content="2021-09-28T00:00:00+00:00"><meta property="og:site_name" content="idk">
<meta property="article:published_time" content="2021-09-28 00:00:00 +0000 UTC">
</head>
<body>
<div class=container>
<header class=header>
<span class=header__inner>
<a href=/ style=text-decoration:none>
<div class=logo>
title
</div>
</a>
<span class=header__right>
<nav class=menu>
<ul class=menu__inner><li><a href=/posts>notes</a></li>
</ul>
</nav>
<span class=menu-trigger><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M0 0h24v24H0z" fill="none"/><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/></svg>
</span>
<span class="theme-toggle not-selectable"><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M22 41c10.4934.0 19-8.5066 19-19C41 11.5066 32.4934 3 22 3 11.5066 3 3 11.5066 3 22s8.5066 19 19 19zM7 22C7 13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22z"/></svg></span>
</span>
</span>
</header>
<div class=content>
<main class=posts>
<div class=posts-info>
<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg>
5 minutes
</p>
</div>
<article>
<h1 class=posts-title>
<a href=https://rand-notes.github.io/fi/ma012/0/>ma012 lec0</a>
</h1>
<div class=posts-content>
<blockquote>
<p>A bell curve is a graph depicting the normal distribution</p>
</blockquote>
<h1 id=p-value>p-value</h1>
<p>A p-value is a measure of the probability that an observed difference could have occurred just
by random chance. p-values are numbers in interval (0, 1) and commonly used threshold is 0.05.
The lower the p-value, the greater the statistical significance of the observed difference.
While a small p-value helps us decide if one group differs from another, it does not tell us how
different they are.</p>
<p>e.g.<br>
two groups (A: 73, B:125) and (A: 71, B: 127) results in p-value P=0.9. This means that the
difference is too small for us to be confident about it.</p>
<hr>
<p>two groups (A: 60, B:138) and (A: 84, B: 114) - (30% vs 42%) results in p-value P=0.01, thus we
can say that these groups differs.</p>
<p>However it might be just an coincidence, if we get a small p-value when there is no difference,
it&rsquo;s called a <strong>False Positive</strong></p>
<hr>
<p>If we need to be really sure the results are correct, we use smaller threshold. e.g. using a
threshold 0.00001 means that we would get a False Positive only once every 100 000 experiments.</p>
<h1 id=central-limit-theorem>Central Limit Theorem</h1>
<p>The central limit theorem (CLT) states that the distribution of sample means approximates a normal distribution as the sample size gets larger, regardless of the population&rsquo;s distribution.</p>
<h1 id=population-distribution>Population Distribution</h1>
<p>The population is the whole set of values, we are interested in.</p>
<h1 id=sample-distribution>Sample Distribution</h1>
<p>The sample is a subset of the population, and the set of values you actually use in your
estimation.</p>
<h1 id=sampling-distribution>Sampling Distribution</h1>
<p>Researchers often use a sample to draw inferences about the population that sample is from. To
do that, they make use of a probability distribution that is very important in the world of
statistics: the sampling distribution.</p>
<h1 id=descriptive-statistics>Descriptive statistics</h1>
<ul>
<li>summarizes sample data via summarization techniques and indexes</li>
<li>frequency tables, moments (mean, variance, skewness, kurtoisis) and quantiles (median, quartiles, interquartiles spans), contingency tables, correlation coefficients</li>
</ul>
<h1 id=frequency-distribution-ie-frequency-listtable>Frequency distribution i.e. frequency list/table</h1>
<p>is a list, table or graph that display the frequency of various outcomes in a sample</p>
<h1 id=exploratory-data-analysis-eda>Exploratory Data Analysis (EDA)</h1>
<ul>
<li>analysis of sample data, usually via visualization methods</li>
<li>frequency plots, boxplots, histograms, scatter plots, PCA</li>
</ul>
<h1 id=statistical-inference>Statistical Inference</h1>
<ul>
<li>derives probability properties (arguments, distribution) of population based on analysis of sample data</li>
<li>requires a model - establishing a assumptions about population and data sample</li>
<li>point and interval parameter estimates (confidence intervals), testing statistics hypothesis, predictions, classifications, clustering</li>
</ul>
<h1 id=parametric-methods>Parametric methods</h1>
<ul>
<li>model establish probability distribution or some set, parameters are being examined via these probability distributions</li>
<li>most of classic methods like t-test, linear regression model, Multivariate regression</li>
</ul>
<h1 id=nonparametric-methods>Nonparametric methods</h1>
<p>or distribution-free statistical methods do not depend on having a normal distribution and can be used with skewed data or with categorical data (Spearman&rsquo;s rho, Mann-Whitney, Wilcoxon Test)</p>
<h1 id=semiparametric-methods>Semiparametric methods</h1>
<ul>
<li>combination of parametric and nonparametric mothods</li>
<li>Cox model of proportional risks in survival analysis</li>
</ul>
<h1 id=nominal-data-categorical>Nominal data (categorical)</h1>
<p>distinguishes different categories for qualitative variables;
dummy code: gender, ethnic background
R: factor</p>
<h1 id=ordinal-data>Ordinal data</h1>
<p>data exists in categories that are ordered but differences cannot be determined or they are meaningless. (Example: 1st, 2nd, 3rd)
R: ordered factor</p>
<h1 id=interval-data>Interval data</h1>
<p>Differences between values can be found, but there is no absolute 0. (Temp. and Time),
R: numeric</p>
<h1 id=ratio-data>Ratio Data</h1>
<p>data with an absolute 0. Ratios are meaningful. (Length, Width, Weight, Distance)</p>
<h1 id=null-hypothesis-h0>Null Hypothesis (H0)</h1>
<p>a statement that the performance of treatment groups is so similar that the groups must belong to the same population; a way of saying that the experimental manipulation had no important effect</p>
<ul>
<li>all level factors have same mean values</li>
</ul>
<h1 id=alternative-hypothesis-h1>Alternative hypothesis (H1)</h1>
<p>The hypothesis that states there is a difference between two or more sets of data.</p>
<ul>
<li>at least one pair of level factors differ in mean value</li>
</ul>
<h1 id=significance-level-alpha>significance level (alpha)</h1>
<p>The acceptable level of error selected by the researcher, usually set at 0.05;
what we compare our p-value to</p>
<h1 id=power-of-a-test>Power of a test</h1>
<ul>
<li>The probability of correctly detecting a false null hypothesis</li>
<li>could be increased by increasing sample data size</li>
</ul>
<h1 id=classical-statistical-hypothesis-testing-according-to-critical-field>classical statistical hypothesis testing; according to critical field</h1>
<ul>
<li>establish H0 and H1</li>
<li>establish model - i.e. statistics assumptions</li>
<li>choose test and testing statistics T with known probability distribution (under the validity of H0)</li>
<li>choose significance level (α) - usually 0.05</li>
<li>compute observed values <em>t</em> of testing statistics <em>T</em></li>
<li>establish critical region <em>W</em> according to <em>H1</em> and <em>t</em></li>
<li>H0 is rejected, if $$t \in W$$</li>
</ul>
<h1 id=statistical-hypothesis-testing-via-p-value>statistical hypothesis testing; via p-value</h1>
<ul>
<li>compute p-value <em>p</em></li>
<li>H0 is rejected, if $$p \lt \alpha$$</li>
</ul>
<h1 id=p-value-1>p-value</h1>
<p>The probability level which forms basis for deciding if results are statistically significant (not due to chance).</p>
<h1 id=t-test>t-test</h1>
<p>a statistical test used to evaluate the size and significance of the difference between two means</p>
<h1 id=multiple-testing>multiple testing</h1>
<p>the more statistical tests we do, the more likely we are to make an erroneous inference (unless we adjust our significance threshold).</p>
<h1 id=anova-analysis-of-variance>ANOVA (analysis of variance)</h1>
<p>-differences among MEANS of continuous (numerical) variables
-more flexible than t-tests&ndash;>can analyze differences among MORE THAN 2 groups (even if diff sample sizes)</p>
<h1 id=multiple-comparison-tests>multiple comparison tests</h1>
<p>statistical tests used to make pairwise comparisons to find which means differ significantly from one another in a one-factor multilevel design</p>
<ul>
<li>Tukey or Scheffe method</li>
</ul>
<h1 id=tukeys-method>Tukey&rsquo;s method</h1>
<p>it&rsquo;s preferred especially in case that all partial random selections have approximately same range</p>
<h1 id=scheffe-method>Scheffe method</h1>
<p>it&rsquo;s recommended especially in case that partial random selections have distinctly different ranges.</p>
<h1 id=the-means--minimalni-nulovy-model>The means / minimalni (nulovy) model</h1>
<p>$$Y_{i,j} = \mu + \epsilon_{i,j}$$</p>
<ul>
<li>\mu (micro, u) - grand mean of Y, same for all levels of factor A</li>
<li>eps - stochaistic independent random variables with probability distribution N(0, \o^2)</li>
</ul>
<h1 id=the-effect-model--jednoducheho-trideni>The effect model / jednoducheho trideni</h1>
<p>$$Y_{i,j} = \mu + \alpha + \epsilon_{i,j}$$</p>
<ul>
<li>alpha - effect of i-th level of factor A</li>
</ul>
<h1 id=grand-mean--spolecna-stredni-hodnota>Grand mean / spolecna stredni hodnota</h1>
<p>$$M: \mu^{\wedge} = Y^{\wedge}$$</p>
<h1 id=effect-i-th-category-in-model-m>effect i-th category in model M</h1>
<p>$$\alpha_{i}^{\wedge} = \overline{Y}_{i.} \overline{Y}_{..}$$</p>
<h1 id=mean-value-of-i-th-category-in-model-m>mean value of i-th category in model M</h1>
<p>$$\mu_{i}^{\wedge} = \mu^{\wedge} + \alpha^{\wedge}_{i} = \overline{Y}_{i.}$$</p>
<h1 id=common-part-of-mean-value-in-submodel-m_0>common part of mean value in submodel M_0</h1>
<p>$$\mu^{\wedge} = \overline{Y}$$</p>
<h1 id=square-sums-describing-variability>Square sums describing variability</h1>
<ul>
<li>Total sum of squares , SS / celkovy soucet ctvercu</li>
<li>Between-groups SS / skupinovy soucet ctvercu</li>
<li>Within-groups/error/residual SS / rezidualni soucet ctvercu</li>
</ul>
<h1 id=parameters-estimates-in-models>Parameters estimates in models</h1>
<ul>
<li>Gran mean / spolecna stredni hodnota</li>
<li>effect i-th category in model M</li>
<li>mean value of i-th category in model M</li>
<li>common part of mean value in submodel M_0</li>
</ul>
</div>
</article>
<hr>
<div class=posts-info>
<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="16" y1="13" x2="8" y2="13"/><line x1="16" y1="17" x2="8" y2="17"/><polyline points="10 9 9 9 8 9"/></svg>
1051 Words
</p>
<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>
2021-09-28
</p>
</div>
<div class=pagination>
<div class=pagination__title>
<span class=pagination__title-h></span>
<hr>
</div>
<div class=pagination__buttons>
<span class="button previous">
<a href=https://rand-notes.github.io/fi/ma012/conf-intervals/>
<span class=button__icon>←</span>
<span class=button__text>Confidence Intervals</span>
</a>
</span>
<span class="button next">
<a href=https://rand-notes.github.io/iv111/0/>
<span class=button__text>IV111 lec 03</span>
<span class=button__icon>→</span>
</a>
</span>
</div>
</div>
</main>
</div>
<footer class=footer>
</footer>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script>
</div>
<script type=text/javascript src=/bundle.min.b2a4161afad463d91113a005f8f24a5efff27a6cc48754e9e93adc7bccb8a876a153a953c0b12653f3b5910e41e620da731f8184f2973058100d159c09fa8346.js integrity="sha512-sqQWGvrUY9kRE6AF+PJKXv/yemzEh1Tp6Trce8y4qHahU6lTwLEmU/O1kQ5B5iDacx+BhPKXMFgQDRWcCfqDRg=="></script>
</body>
</html>